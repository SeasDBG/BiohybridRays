{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing Search Algorithms - CMA-ES\n",
    "#Disease Biophysics Group\n",
    "#Written by John Zimmerman\n",
    "#Updated 4/22/21\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "#from scipy import interpolate\n",
    "import scipy.interpolate\n",
    "import scipy.stats\n",
    "import math\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import GeoSwimmer\n",
    "import statsmodels.api as sm\n",
    "from cmaes import CMA, get_warm_start_mgd\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.compat.v2.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenFooDataframe(dnaLength):\n",
    "    #---Make Swimmer Dataframe with Foo Velocity Labels ---\n",
    "    #Takes ~15 min to run\n",
    "    print('Generating Foo dataframe. Takes ~15 min')\n",
    "    #Generate List of all possible swimmers\n",
    "    dnaAlphabet = SwimDNA.DNABasis()\n",
    "    fullswimlist = [''.join(i) for i in product(dnaAlphabet, repeat = dnaLength)]\n",
    "    fullswimlist = fullswimlist[1:-1]\n",
    "    df = pd.DataFrame({'DNA':fullswimlist})\n",
    "\n",
    "    #SampleSwim = Swimlist.sample(100000,random_state=seed)\n",
    "    print('Label Velocities...')\n",
    "    dfLabels = df.DNA.apply(SwimVel.gen_approx_swim_vels, args=(.5,0.0,0.0,0,.05)) \n",
    "    print('Done')\n",
    "\n",
    "    alphabetVectors = RadarPlot.constructRadarBasis(SwimDNA.DNABasis())\n",
    "    print('Radar Points...')\n",
    "    RadarPoints = df.DNA.apply(RadarPlot.DNARadarPointsList, args=(alphabetVectors,))\n",
    "    RadarPoints = pd.DataFrame(RadarPoints.to_list(),columns=['RadX','RadY'])\n",
    "    print('Done')\n",
    "\n",
    "    df['RadX']=RadarPoints.RadX.to_list()\n",
    "    df['RadY']=RadarPoints.RadY.to_list()\n",
    "    df['Label'] = dfLabels\n",
    "    return df\n",
    "\n",
    "class SwimSearch:\n",
    "    def seededList(df):\n",
    "        alphabet = SwimDNA.DNABasis()\n",
    "        seedlist=  np.array([])\n",
    "        for a in alphabet[1:-1]:\n",
    "            seedlist = np.append(seedlist,(a*6))\n",
    "            seedlist = np.append(seedlist,a+alphabet[0]*5)\n",
    "            seedlist = np.append(seedlist,a+alphabet[-1]*5)\n",
    "        \n",
    "        seed = pd.DataFrame({'DNA':seedlist})\n",
    "        seed = df[df.DNA.isin(seed.DNA)]\n",
    "        \n",
    "        return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwimDNA:\n",
    "    def getWeights(DNA):\n",
    "        weights = np.ones(len(DNA))\n",
    "        m = -1/float(len(DNA))\n",
    "        b = 1\n",
    "        for i in range(0,len(DNA)):\n",
    "            weights[i] = m*i+b\n",
    "        weights = weights/np.sum(weights)\n",
    "        return weights\n",
    "\n",
    "    def string_to_matrix(string):\n",
    "        matrix = np.zeros((14,len(string)), dtype=np.int8)\n",
    "        for position, letter in enumerate(string):\n",
    "            num = (ord(letter.upper()) - 65) % 14\n",
    "            matrix[num, position] = 1\n",
    "        return matrix\n",
    "\n",
    "    \n",
    "    def DNABasis():\n",
    "        return ['A','B','C','D','E','F','G','H','I','J','K','L','M','N']\n",
    "    \n",
    "    def avgDnaListDistance(dnalist):\n",
    "        #Feed in dataframe.DNA list\n",
    "        avglist = np.zeros(dnalist.size) #Declare List for storing Averages\n",
    "\n",
    "        for DNA1,i in zip(dnalist,np.arange(dnalist.size)): #Cycled through each DNA\n",
    "            dist = 0\n",
    "            for DNA2 in dnalist: #Compare to Each Other DNA in database\n",
    "                if DNA1 != DNA2:\n",
    "                    dist += SwimDNA.dnaDistance(DNA1,DNA2)\n",
    "            dist = dist/float(dnalist.size-1) #Average Out Values\n",
    "            avglist[i] = dist\n",
    "        return avglist\n",
    "\n",
    "    def dnaDistance(DNA1,DNA2):\n",
    "        vector1 = SwimDNA.DNAVector(DNA1)\n",
    "        vector2 = SwimDNA.DNAVector(DNA2)\n",
    "        dist = 0\n",
    "        for a in SwimDNA.DNABasis():\n",
    "            dist += (vector1[a]-vector2[a])**2\n",
    "\n",
    "        return np.sqrt(dist)\n",
    "\n",
    "    def DNAVector(DNA):\n",
    "        weights = SwimDNA.getWeights(DNA)\n",
    "        vector = {a:0 for a in SwimDNA.DNABasis()}\n",
    "        num = np.arange(len(DNA))\n",
    "\n",
    "        for a,i in zip(DNA,num):\n",
    "                    vector[a]+=1*weights[i]\n",
    "        return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    \n",
    "    def OneHotEncodeList (SwimList):\n",
    "        trainMatrix  =np.zeros((SwimList.DNA.size,14,len(SwimList.DNA.iloc[0])))\n",
    "\n",
    "        i=0\n",
    "        for DNA in SwimList.DNA:\n",
    "            trainMatrix[i,:,:] = SwimDNA.string_to_matrix(DNA)\n",
    "            i+=1\n",
    "\n",
    "        trainMatrix= tf.convert_to_tensor(trainMatrix,dtype=tf.float16)    \n",
    "        return trainMatrix\n",
    "\n",
    "    def LabelTensor (SwimList):\n",
    "        labelMatrix  =np.zeros(SwimList.Label.size)\n",
    "\n",
    "        i=0\n",
    "        for DNA in SwimList.DNA:\n",
    "            trainMatrix[i,:,:] = SwimDNA.string_to_matrix(DNA)\n",
    "            i+=1\n",
    "\n",
    "        trainMatrix= tf.convert_to_tensor(trainMatrix,dtype=tf.float32)    \n",
    "        return trainMatrix\n",
    "\n",
    "    def genNNModel(InputLength):\n",
    "        model = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Flatten(input_shape=(14, InputLength)),\n",
    "          tf.keras.layers.Dense(14, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.2),\n",
    "          tf.keras.layers.Dense(14*14, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.2),\n",
    "          tf.keras.layers.Dense(14, activation='relu'),\n",
    "          tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "   \n",
    "    def genNN_MatMul_model(InputLength):# define two sets of inputs\n",
    "        inputA = tf.keras.Input(shape=(14,InputLength))\n",
    "\n",
    "        # Dense Input Branch - Make a 14 dim vector\n",
    "        x = tf.keras.layers.Flatten()(inputA)\n",
    "        x = tf.keras.layers.Dense(14, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Reshape((14, 1))(x)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.Model(inputs=inputA, outputs=x)\n",
    "        \n",
    "        #Build cross-correlation Matrix\n",
    "        y = tf.keras.layers.Flatten()(inputA)\n",
    "        y = tf.keras.layers.Dense(14*14, activation=\"relu\")(y)\n",
    "        y = tf.keras.layers.Reshape((14, 14))(y)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        y = tf.keras.Model(inputs=inputA, outputs=y)\n",
    "\n",
    "        \n",
    "        #combine the output of the two branches\n",
    "        combined = tf.linalg.matmul(y.output, x.output)\n",
    "\n",
    "        # Combined Outputs\n",
    "        z = tf.keras.layers.Flatten()(combined)\n",
    "        z = tf.keras.layers.Dense(14, activation=\"relu\")(z)\n",
    "        z = tf.keras.layers.Dropout(0.2)(z)\n",
    "        z = tf.keras.layers.Dense(6, activation=\"relu\")(z)\n",
    "        z = tf.keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "\n",
    "        #Combined model outputs join of branches\n",
    "        model = tf.keras.models.Model(inputs=[inputA], outputs=z)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def genNN_mixed_model(InputLength):# define two sets of inputs\n",
    "        inputA = tf.keras.Input(shape=(14,InputLength))\n",
    "\n",
    "        # Dense Input Branch\n",
    "        x = tf.keras.layers.Flatten()(inputA)\n",
    "        x = tf.keras.layers.Dense(14, activation=\"relu\")(x)\n",
    "        #x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.Model(inputs=inputA, outputs=x)\n",
    "        \n",
    "        #inputB = tf.reshape(inputA,(-1,14,InputLength,1))\n",
    "        # the second branch opreates on the second input\n",
    "        y = tf.keras.layers.Reshape((-1, -1, 1))(inputA)\n",
    "        y = tf.keras.layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same')(y)\n",
    "        y = tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same')(y)\n",
    "        #y = tf.keras.layers.BatchNormalization()(y)\n",
    "        y = tf.keras.layers.Dropout(0.2)(y)\n",
    "        y = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(y)\n",
    "        y = tf.keras.layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(y)\n",
    "        #y = tf.keras.layers.BatchNormalization()(y)\n",
    "        y = tf.keras.layers.Dropout(0.2)(y)\n",
    "        y = tf.keras.layers.Reshape((14, InputLength))(inputA)\n",
    "        y = tf.keras.layers.Flatten()(y)\n",
    "        y = tf.keras.layers.Dense(14, activation=\"relu\")(y)\n",
    "        #y = tf.keras.layers.BatchNormalization()(y)\n",
    "        y = tf.keras.Model(inputs=inputA, outputs=y)\n",
    "        \n",
    "        #combine the output of the two branches\n",
    "        combined = tf.keras.layers.add([x.output, y.output])\n",
    "        #combined = tf.keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "        # Combined Outputs\n",
    "        z = tf.keras.layers.Flatten()(combined)\n",
    "        z = tf.keras.layers.Dense(14, activation=\"relu\")(z)\n",
    "        z = tf.keras.layers.Dropout(0.2)(z)\n",
    "        z = tf.keras.layers.Dense(6, activation=\"relu\")(z)\n",
    "        z = tf.keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "\n",
    "        #Combined model outputs join of branches\n",
    "        model = tf.keras.models.Model(inputs=[inputA], outputs=z)\n",
    "        return model\n",
    "    \n",
    "    def genNNModelLim(InputLength):\n",
    "        tf.keras.backend.set_floatx('float64')\n",
    "        model = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Flatten(input_shape=(14, InputLength)),\n",
    "          tf.keras.layers.Dense(14, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.1),\n",
    "          #tf.keras.layers.Dense(32, activation='relu'),\n",
    "          #tf.keras.layers.Dropout(0.1),\n",
    "          tf.keras.layers.Dense(14, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.1),\n",
    "          #tf.keras.layers.Dense(64, activation='relu'),\n",
    "          tf.keras.layers.Dense(14, activation='relu'),\n",
    "          tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    def NNOptimizer(lr=0.001,epsilon=1e-07,amsgrad=False):\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr, epsilon=epsilon, amsgrad=amsgrad, name='Adam')\n",
    "    \n",
    "    def cum_KL_divergence(ge_c,ge_mean,ge_sigma):\n",
    "        def KL_div(cdf_pred, cdf_true):\n",
    "            P = NN.TF_pdf(NN.TF_ppf(cdf_pred,ge_c,ge_mean,ge_sigma),ge_c,ge_mean,ge_sigma) #CDF -> PDF\n",
    "            Q = NN.TF_pdf(NN.TF_ppf(cdf_true,ge_c,ge_mean,ge_sigma),ge_c,ge_mean,ge_sigma)  #CDF -> PDF\n",
    "            P = tf.where(tf.math.is_nan(P),tf.convert_to_tensor(0.000001,dtype=tf.float64),P)\n",
    "            Q = tf.where(tf.math.is_nan(Q),tf.convert_to_tensor(0.000001,dtype=tf.float64),Q)\n",
    "\n",
    "            return tf.math.square(cdf_pred-cdf_true)#+P*tf.math.log(P/Q)\n",
    "        return KL_div\n",
    "\n",
    "    \n",
    "    def TF_ppf(q,c,mean,sigma):\n",
    "        x=-tf.math.log(-tf.math.log(q))\n",
    "        \n",
    "        return tf.where((c == 0) & (x == x),x,-tf.math.expm1(-c *x )/c)*sigma+mean\n",
    "    \n",
    "    def TF_pdf(x,c,mean,sigma):\n",
    "        z = (x-mean)/sigma\n",
    "        return tf.where((c==0),tf.math.exp(z)*tf.math.exp(-1*tf.math.exp(z)),tf.math.exp(-(1-c*z)**(1/c))*(1-c*z)**(1/c-1))*(1/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(truth,label):\n",
    "    return np.sqrt((truth-label)**2).sum()\n",
    "\n",
    "def Train_Loop(savepath,loadpath, seed=12345, InitialNumbers=1000,testNum=1000,epochsperloop=100,loops=10,simsperloop=100, save=False,method='Random',lr=0.001,epsilon=1e-07):\n",
    "\n",
    "        df = pd.read_pickle(loadpath+'results2.pkl')\n",
    "        dnaLength = len(df.DNA[0])\n",
    "        #print(f'DNAL: {dnaLength}')\n",
    "\n",
    "        #Initial Training Data/ Test Data Sampling\n",
    "        train = SwimSearch.seededList(df) #Seed with some selected basis functions (BAAAAA,BNNNNN,BAAAAA)\n",
    "        remain = InitialNumbers-train.DNA.size\n",
    "        train = train.append(df[~df.DNA.isin(train.DNA)].sample(remain,random_state=seed)) \n",
    "        \n",
    "        #Initialize Model\n",
    "        #optimizer = CMA(mean=)\n",
    "        \n",
    "        if save:\n",
    "            TopPercentile = np.zeros(loops)\n",
    "\n",
    "        for loopnum in range(0,loops):\n",
    "            print(f'Train min Value: {train.Label.min()}')\n",
    "            print(f'Train Max Value: {train.Label.max()}')\n",
    "\n",
    "            #Reset Model - Reloading Weights\n",
    "            model.load_weights(savepath+'model.h5')\n",
    "\n",
    "            #Prepare Samples for Model\n",
    "            test = df[~df.DNA.isin(train.DNA)].sample(testNum,random_state=seed+1+loopnum*simsperloop) #Generate Test Set of Swimmers\n",
    "            rescale_max =  train.Label.max()*1.5\n",
    "            rescale_min =  train.Label.min()*1.5\n",
    "\n",
    "            OH_train = NN.OneHotEncodeList(train) #One Hot encoded tensor\n",
    "            OH_test = NN.OneHotEncodeList(test) #One Hot encoded tensor\n",
    "            #train_label = tf.convert_to_tensor(train.Label.to_numpy(),dtype=tf.float32)\n",
    "            #test_label = tf.convert_to_tensor(test.Label.to_numpy(),dtype=tf.float32)\n",
    "            train_label = tf.convert_to_tensor(SwimSearch.normalizeArray(train.Label.to_numpy(),rescale_min,rescale_max),dtype=tf.float32)\n",
    "            test_label = tf.convert_to_tensor(SwimSearch.normalizeArray(test.Label.to_numpy(),rescale_min,rescale_max),dtype=tf.float32)\n",
    "\n",
    "            #Fit Model to data\n",
    "            model.fit(OH_train, train_label, epochs=epochsperloop)\n",
    "            print(f'Loop {loopnum} MSE: {np.average((test.Label.to_numpy()-SwimSearch.rescaleArray(model(OH_test,training=False).numpy(),rescale_min,rescale_max))**2)}')\n",
    "\n",
    "            #Update Model Label\n",
    "            print('Updating Model Label...')\n",
    "            df['ModelLabel'] = SwimSearch.rescaleArray(model(OH_df,training=False).numpy(),rescale_min,rescale_max)\n",
    "            #df['ModelLabel'] = model(NN.OneHotEncodeList(df)).numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            train = searchmethod(df,train,simsperloop,loopnum,seed)\n",
    "            \n",
    "            if save:\n",
    "                sample = df.sample(50000,random_state=seed)\n",
    "                OH_sample = NN.OneHotEncodeList(sample)\n",
    "                fig = RadarPlot.PlotRadarMesh(sample.RadX,sample.RadY,sample.ModelLabel,figwidth=9,figheight=6.5,vmin=df.Label.min(),vmax=df.Label.max(),res=100)\n",
    "                savefig(savepath+'Model_'+method+'_seed'+str(seed)+'_LoopNum'+str(loopnum)+'.png')\n",
    "                clf()\n",
    "                close()\n",
    "                \n",
    "                TopPercentile[loopnum] = SwimSearch.top_predicted(df,2000)\n",
    "            \n",
    "        \n",
    "        if save:\n",
    "            np.savetxt(savepath+'TopPerc2000_'+method+'_seed'+str(seed)+'.txt',TopPercentile)\n",
    "        #return train\n",
    "        return model, df, rescale_min, rescale_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeTraining(df,initialNumber,seed):\n",
    "    train = SwimSearch.seededList(df) #Seed with some selected basis functions (BAAAAA,BNNNNN,BAAAAA)\n",
    "    remain = initialNumber-train.DNA.size\n",
    "    train = train.append(df[~df.DNA.isin(train.DNA)].sample(remain,random_state=seed))\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = InitializeTraining(df,InitialtrainNum,seedlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_NumSeq(num_sequence, target, df):\n",
    "    #print(num_sequence)\n",
    "    DNA = SequenceToDNA(num_sequence)\n",
    "    print(DNA)\n",
    "    label = df[df.DNA==DNA].Label.to_list()[0]\n",
    "    return np.sqrt((target-label)**2)\n",
    "\n",
    "def Evaluate_DNA(DNA, target, df):\n",
    "    print(DNA)\n",
    "    label = df[df.DNA==DNA].Label.to_list()[0]\n",
    "    return np.sqrt((target-label)**2)\n",
    "\n",
    "def DNA_ToArray(DNA):\n",
    "    seq = np.zeros(len(DNA))\n",
    "    for (letter,i) in zip(DNA,range(0,len(DNA))):\n",
    "        seq[i] = ord(letter)-65\n",
    "    return seq\n",
    "        \n",
    "def SequenceToDNA(seq):\n",
    "    int_seq = np.rint(seq)\n",
    "    string = ''\n",
    "    for i in int_seq:\n",
    "        string += chr(65+int(i))\n",
    "    return string\n",
    "\n",
    "def Eval_top_predicted(evaluated_DF, dataframe,num=2000):\n",
    "    topLabel = dataframe.nlargest(num,\"Label\")\n",
    "    #topModel = dataframe.nlargest(num,\"ModelLabel\")\n",
    "    correct = evaluated_DF[evaluated_DF.DNA.isin(topLabel.DNA)==True].DNA.size\n",
    "    print(f'correct: {correct}')\n",
    "    return correct\n",
    "\n",
    "#DNA_ToArray('NGGGGG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CMAES_TrainLoop(savepath,loadpath, seed=12345, sigma = 1.5, InitialNumbers=400,loops=10,simsperloop=50, save=False):\n",
    "    initial_mean = np.zeros(6)\n",
    "    initial_mean[:] = 7\n",
    "    target = df.nlargest(1,\"Label\").Label.to_list()[0]\n",
    "    bounds = np.array([[0,13],[0,13],[0,13],[0,13],[0,13],[0,13]])\n",
    "    optimizer = CMA(mean=initial_mean, sigma=sigma, bounds=bounds, seed=seed)\n",
    "    \n",
    "    initial_list = InitializeTraining(df,InitialNumbers,seed)\n",
    "    #initial_list = InitializeTraining(df,41,10)\n",
    "    evaluated_list = initial_list.copy()\n",
    "    evaluated_list['Gen'] = -1\n",
    "\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        print('TestSave')\n",
    "        evaluated_list.to_pickle(savepath+'CMAES_Results_'+str(seed)+'.pkl',)\n",
    "    \n",
    "    solutions = []\n",
    "    for DNA in evaluated_list.DNA.to_list():\n",
    "        seq = DNA_ToArray(DNA)\n",
    "        val = Evaluate_DNA(DNA,target,df)\n",
    "        solutions.append((seq, val))\n",
    "    #optimizer.tell(solutions)\n",
    "    \n",
    "    #Warm Start Optimizer\n",
    "    ws_mean, ws_sigma, ws_cov = get_warm_start_mgd(solutions) \n",
    "    optimizer = CMA(mean=ws_mean, sigma=sigma, cov=ws_cov,bounds=bounds, seed=seed, population_size=simsperloop)\n",
    "    \n",
    "    Eval_top_predicted(evaluated_list,df,2000)\n",
    "    evaluated_list['Gen'] = -1\n",
    "    \n",
    "    Predicted = np.array([])\n",
    "    \n",
    "    for generation in range(loops):\n",
    "        print(f'Generation: {generation}')\n",
    "        solutions = []\n",
    "        for _ in range(optimizer.population_size):\n",
    "            x = optimizer.ask()\n",
    "            print(x)\n",
    "            DNA = SequenceToDNA(x)\n",
    "            value = Evaluate_DNA(DNA,target,df)\n",
    "            solutions.append((x, value))\n",
    "            \n",
    "            append_copy = df[df.DNA == DNA].copy()\n",
    "            append_copy['Gen'] = generation\n",
    "            evaluated_list = evaluated_list.append(append_copy)\n",
    "            \n",
    "\n",
    "        optimizer.tell(solutions)\n",
    "        correct = Eval_top_predicted(evaluated_list,df,2000)\n",
    "        Predicted = np.append(Predicted,correct)\n",
    "        \n",
    "        if save:\n",
    "            print('Saving')\n",
    "            evaluated_list.to_pickle(savepath+'CMAES_Results_'+str(seed)+'.pkl')\n",
    "            np.savetxt(savepath+'CMAES_predicted_'+str(seed)+'.txt',Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run An Example Training Model\n",
    "\n",
    "InitialtrainNum = 100#400\n",
    "loops = 8+1+6 #Plus 1 to hit full Amount of 800 Swimmers\n",
    "simsperloop = 50#50\n",
    "save = True\n",
    "loadpath = 'G:\\\\...\\\\'\n",
    "savepath = 'G:\\\\...\\\\'\n",
    "sigma = 13/5\n",
    "\n",
    "seedlist = [1009,1013,1019,1021,1031,1033,1039,1049,1051,1061] #First 10 prime numbers with 4 digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpath = 'G:\\\\...\\\\'\n",
    "#e.g. 'G:\\\\Data Process\\\\NeuralNet\\\\EvaluationMethods\\\\'\n",
    "\n",
    "loadcheck = os.path.exists(loadpath+'results.pkl')\n",
    "if loadcheck == True:\n",
    "    df = pd.read_pickle(loadpath+'results.pkl')\n",
    "    print('Results loaded')\n",
    "else:\n",
    "    df = GenFooDataframe(6)\n",
    "    df.to_pickle(loadpath+'results.pkl')\n",
    "\n",
    "dnaLength = len(df.DNA[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loadpath = 'G:\\\\...\\\\'\n",
    "savepath = 'G:\\\\...\\\\'\n",
    "#e.g. 'G:\\\\Data Process\\\\NeuralNet\\\\EvaluationMethods\\\\'\n",
    "\n",
    "for seednum in seedlist:\n",
    "    CMAES_TrainLoop(savepath,loadpath, seed=seednum, sigma = sigma, InitialNumbers=InitialtrainNum,loops=loops,simsperloop=simsperloop, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_name = 'CMAES_Results_1061'\n",
    "cmaes = pd.read_pickle(savepath+DF_name+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cmaes.Gen.to_numpy()\n",
    "m = m+1\n",
    "\n",
    "fig = figure(figsize=(6,5))\n",
    "scatter(cmaes.RadX.to_list(),cmaes.RadY.to_list(),c=m)\n",
    "cb = colorbar()\n",
    "cb.set_ticklabels(m)\n",
    "xlim(-1.1,1.1)\n",
    "ylim(-1.1,1.1)\n",
    "savefig(savepath+DF_name+'.svg',format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMAES",
   "language": "python",
   "name": "cmaes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
