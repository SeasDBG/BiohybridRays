{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Machine Learning Models and Function\n",
    "#Disease Biophysics Group\n",
    "#Written by John Zimmerman\n",
    "#Updated 4/10/22\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import math \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import *\n",
    "from scipy.spatial import ConvexHull\n",
    "from itertools import product\n",
    "import scipy.stats\n",
    "\n",
    "import GeoSwimmer\n",
    "import SwimNN\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.compat.v2.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normcdf(x, mu, sigma):\n",
    "    t = x-mu;\n",
    "    y = 0.5*erfcc(-t/(sigma*sqrt(2.0)));\n",
    "    if y>1.0:\n",
    "        y = 1.0;\n",
    "    return y\n",
    "\n",
    "def updateModelLabels(df,model,chunksize=4, dualloss = False):\n",
    "    splits = int(np.round(df.DNA.size/chunksize))\n",
    "    breakList = list(SwimNN.SwimSearch.chunks(np.arange(df.DNA.size),splits))\n",
    "    \n",
    "    modelLabel = np.zeros(df.DNA.size)\n",
    "    print('Updating Labels')\n",
    "    for breaks in breakList:\n",
    "        print(f'{(breaks[-1]/df.DNA.size)*100:.2f}%...')\n",
    "        dfchunk = df[breaks[0]:breaks[-1]+1]\n",
    "        OH_df = SwimNN.NN.OneHotEncodeList(dfchunk)\n",
    "        if dualloss:\n",
    "            #modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df[breaks[0]:breaks[-1]+1],training=False)[0].numpy().reshape(-1) #Multiloss\n",
    "            modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df,training=False)[0].numpy().reshape(-1)\n",
    "        else:\n",
    "            modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df,training=False).numpy().reshape(-1)\n",
    "            #modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df[breaks[0]:breaks[-1]+1],training=False).numpy().reshape(-1)\n",
    "\n",
    "    return modelLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load File Paths\n",
    "filepath = 'G:\\\\...\\\\'\n",
    "filename = 'results_updated.pkl'\n",
    "df = pd.read_pickle(filepath+filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[~df['SimNetU'].isna()].sample(1500)\n",
    "sim = df[~df['SimNetU'].isna()]\n",
    "validate = sim[~sim.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model validation on swimmer data set, and looking for top ranked swimmers for final iteration\n",
    "#Update NN Model\n",
    "dnaLength = 6\n",
    "lr=0.001\n",
    "epsilon=1e-07\n",
    "epochsperloop = 8000\n",
    "updatechunks = 32\n",
    "number = 1200\n",
    "loadweights = False\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = SwimNN.NN.Hessian_DualLoss_refine(dnaLength)\n",
    "\n",
    "#loadweights = os.path.exists(filepath+'model.h5')\n",
    "\n",
    "if loadweights == False:\n",
    "    print('No Model Weights found...proceeding with fresh weights') \n",
    "else:\n",
    "    print('Loading Model weights...')\n",
    "    model.load_weights(filepath+'model.h5') \n",
    "    print('Model Loaded')\n",
    "\n",
    "\n",
    "train = df[df[\"SimNetU\"].notna()].sample(number)\n",
    "sim = df[~df['SimNetU'].isna()]\n",
    "validate = sim[~sim.index.isin(train.index)]\n",
    "print(f'Train min Value: {train[\"SimNetU\"].min()}')\n",
    "print(f'Train Max Value: {train[\"SimNetU\"].max()}')\n",
    "\n",
    "#Estimate CDF of Training Samples\n",
    "train_vels = np.array(train[\"SimNetU\"].to_list()) #Convert of Array\n",
    "\n",
    "print('Fitting CDF to array')\n",
    "train['CDF'] =  scipy.stats.norm.cdf(train.SimNetU,np.mean(train.SimNetU),np.std(train.SimNetU))\n",
    "validate['CDF'] = scipy.stats.norm.cdf(validate.SimNetU,np.mean(train.SimNetU),np.std(train.SimNetU))\n",
    "\n",
    "#Generate training inputs for model\n",
    "OH_train =tf.cast(SwimNN.NN.OneHotEncodeList(train),tf.float64)\n",
    "train_label = tf.convert_to_tensor(train.CDF.to_numpy(),dtype=tf.float64)\n",
    "\n",
    "#Prep Model\n",
    "loss = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "model.compile(optimizer=SwimNN.NN.NNOptimizer(lr=lr,epsilon=epsilon),\n",
    "          loss=(loss,loss),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "#Fit Model to data - Two Labels for Multiloss\n",
    "model.fit(OH_train, (train_label,train_label), epochs=epochsperloop)\n",
    "\n",
    "\n",
    "df['ModelLabel'] = updateModelLabels(df,model,chunksize=updatechunks, dualloss=True)\n",
    "validate['ModelLabel'] = updateModelLabels(validate,model,chunksize=1, dualloss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding middle of the road swimmers\n",
    "count = 8\n",
    "\n",
    "midsample = df[df[\"ModelLabel\"]>0.49]\n",
    "midsample = midsample[midsample[\"ModelLabel\"]<0.51]\n",
    "\n",
    "sortedDF = midsample.sort_values(\"ModelLabel\")\n",
    "length = np.floor(len(sortedDF.DNA)/2)\n",
    "print(length)\n",
    "\n",
    "\n",
    "minloc = int(length-count) \n",
    "maxloc = int(length+count)\n",
    "sortedDF[minloc:maxloc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph energy landscape of the results\n",
    "sample = df.sample(30000)\n",
    "fig = SwimNN.RadarPlot.PlotRadarMesh(sample.RadX,sample.RadY,sample.ModelLabel,figheight=10,figwidth=10)\n",
    "sim = df[~df['SimNetU'].isna()]\n",
    "scatter(sim.RadX,sim.RadY,c=\"black\",s=10,alpha=0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_LBM",
   "language": "python",
   "name": "tf_lbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
