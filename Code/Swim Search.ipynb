{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lattice Boltzman D3Q15 Simulation of Swimmers with Search\n",
    "#Disease Biophysics Group\n",
    "#Written by John Zimmerman\n",
    "#Updated 9/08/22\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import *\n",
    "from scipy.spatial import ConvexHull\n",
    "from itertools import product\n",
    "import scipy.stats\n",
    "\n",
    "import GeoSwimmer\n",
    "import DBG_LBM\n",
    "import SwimMesh\n",
    "import SwimNN\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.compat.v2.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarySign(xarray):\n",
    "    xarray[xarray>0] = 1.0\n",
    "    xarray[xarray<0] = -1.0\n",
    "    return xarray\n",
    "\n",
    "def evaluateswimmer(Vels,swimname,minx=25,miny=0,maxy=120, savepath=''):\n",
    "    cycletime = Vels.shape[0]\n",
    "    total_grid_size_x = Vels.shape[1]\n",
    "    total_grid_size_y = Vels.shape[2]\n",
    "    total_grid_size_z = Vels.shape[3]\n",
    "    \n",
    "    maxx = total_grid_size_x-minx\n",
    "    \n",
    "    #Setup Data Arrays\n",
    "    U = np.array([])\n",
    "    V = np.array([])\n",
    "    uv = np.zeros((cycletime,2))\n",
    "    for i in range(0,cycletime):\n",
    "        #Find Sum of Velocities\n",
    "        u = np.sum(np.mean(Vels[i,minx:maxx,miny:maxy,:,0],axis=-1)-np.mean(Vels[0,minx:maxx,miny:maxy,:,0],axis=-1))\n",
    "        v = np.sum(np.mean(Vels[i,minx:maxx,miny:maxy,:,1],axis=-1)-np.mean(Vels[0,minx:maxx,miny:maxy,:,1],axis=-1))\n",
    "        if savepath != '':\n",
    "            uv[i,0] = u\n",
    "            uv[i,1] = v\n",
    "        U = np.append(U,u)\n",
    "        V = np.append(V,v)\n",
    "    \n",
    "    #Drift correct\n",
    "    t = np.linspace(0,1,U.size)\n",
    "    U = U - ((U[-1]-U[0])/t[-1])*t\n",
    "    V = V - ((V[-1]-V[0])/t[-1])*t\n",
    "    \n",
    "    if savepath != '':\n",
    "        #UV drift correct\n",
    "        uv[:,0] = uv[:,0]-(uv[-1,0]-uv[0,0])*t\n",
    "        uv[:,1] = uv[:,1]-(uv[-1,1]-uv[0,1])*t\n",
    "    \n",
    "    NetU = np.sum(U)\n",
    "    hc = int(np.round(cycletime/2)) #half cycletime\n",
    "    EF = np.sum(np.abs(U[:hc]))/(np.sum(np.abs(U[:hc]))+np.sum(np.abs(V[:hc])))\n",
    "    \n",
    "    if savepath != '':\n",
    "        np.savetxt(savepath+swimname+'_UV.txt',uv)\n",
    "    \n",
    "    \n",
    "    return NetU,EF\n",
    "\n",
    "\n",
    "def SimSwimmer(swimname,slantangle,total_grid_size_x,total_grid_size_y,total_grid_size_z,shape,swimmass=1,visualize=False,savepath=''):\n",
    "    \n",
    "    #Build a Velocity Array from Your Objects/ MTFs/Swimmers\n",
    "    grid = SwimMesh.genGrid(total_grid_size_x,total_grid_size_y,total_grid_size_z,shape)\n",
    "    \n",
    "    #Generate Swimmer Base Mesh\n",
    "    tri,vertdict = SwimMesh.generateMeshHalf(swimname,40,gscale=wscale,arg='pqa1.2')    \n",
    "    verts = np.array(tri['vertices'])\n",
    "    triangles = tri['triangles']\n",
    "    print(\"Vert Min:\")\n",
    "    print(verts[:,1].min())\n",
    "    print(\"Vert Max:\")\n",
    "    print(verts[:,1].max())\n",
    "    \n",
    "    \n",
    "    print('Solving Grid/Material Interactions...')\n",
    "    #Mindex_build = solve_velocity_grid(verts,triangles,minr,maxr,thic,slantangle,cycletime,profilespline,difspline,grid,shape,streamtime)\n",
    "    Mindex_build = solve_velocity_grid(verts,triangles,minr,maxr,thic,slantangle,cycletime,profilespline,difspline,grid,shape)\n",
    "    ObjVels = tf.constant(tf.convert_to_tensor(Mindex_build.astype(np.float16)/ReductionFactor))\n",
    "    ObjVels = tf.split(ObjVels,cycletime,axis=0)\n",
    "    \n",
    "    #Save kinematics summary\n",
    "    u = np.array([])\n",
    "    v = np.array([])\n",
    "    for obj in ObjVels:\n",
    "        usum =  tf.math.reduce_sum(obj[:,:,:,:,0])\n",
    "        vsum =  tf.math.reduce_sum(obj[:,:,:,:,1])\n",
    "        u = np.append(u,usum)\n",
    "        v = np.append(v,vsum)\n",
    "    kinUV = np.zeros((2,u.shape[0]))\n",
    "    kinUV[0,:] = u\n",
    "    kinUV[1,:] = v\n",
    "    np.savetxt(savepath+str(swimname)+'_UV_kinematics.txt',kinUV)\n",
    "\n",
    "    print('Running Simulation...')\n",
    "    \n",
    "    #Initialize Video\n",
    "    savevidcheck = os.path.exists(savepath+'\\\\CVVideo')\n",
    "    if savevidcheck == False:\n",
    "        os.makedirs(savepath+'\\\\CVVideo')\n",
    "    vidsavepath = savepath+'\\\\CVVideo\\\\'+swimname+'_flow.avi'\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    video = cv2.VideoWriter()\n",
    "    Vsize = int(3)\n",
    "    if (scalemax!=0):\n",
    "        success = video.open(vidsavepath, fourcc, 30, (shape[1]*Vsize, shape[0]*Vsize+20), True)\n",
    "    else:\n",
    "        success = video.open(vidsavepath, fourcc, 30, (shape[1]*Vsize, shape[0]*Vsize), True)\n",
    "\n",
    "    #Initialize Grid - Kinematic Viscocity, Grid Shape, Grid Spacing, Time per frame\n",
    "    totalframes = int(np.round(totalsimtime/dt))\n",
    "    grid = DBG_LBM.Grid(vis,shape,totalframes,dx=dx,dt=dt/float(streamtime),cycletime=cycletime)\n",
    "    \n",
    "\n",
    "    #Material Grid\n",
    "    grid.MIndex.assign(grid.FlowThrough())\n",
    "    grid.swimmass = swimmass\n",
    "    grid.Vel.assign(DBG_LBM.InitialVel(grid.shape)/ReductionFactor)\n",
    "    grid.ObjVels.assign(ObjVels)\n",
    "\n",
    "\n",
    "    #Run Program - grid, number of iterations, How often to Save\n",
    "    #try:\n",
    "    U,V = DBG_LBM.run(grid,totalframes,video,savenum=savenum,cycletime=cycletime,scalemax=scalemax,streamtime=streamtime,debug=False)\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    Vels = grid.ObjVels.numpy()\n",
    "    Vels = Vels.reshape(cycletime,shape[0],shape[1],shape[2],4)\n",
    "    Vels = Vels[:,:,:,:,:3]\n",
    "\n",
    "    RhoScaling = 0.00997*1.02 #g/mm^3\n",
    "    swimvelocities = grid.OutFlux.numpy()\n",
    "\n",
    "\n",
    "    velocitycheck = os.path.exists(savepath+'\\\\SwimVelocities')\n",
    "    if velocitycheck == False:\n",
    "        os.makedirs(savepath+'\\\\SwimVelocities')\n",
    "    velocitysavepath = savepath+'\\\\SwimVelocities\\\\'\n",
    "    np.savetxt(velocitysavepath+swimname+'_velocity.txt',swimvelocities)\n",
    "\n",
    "    traveldistance = np.sum(swimvelocities*dt*dx)\n",
    "\n",
    "    #Save data\n",
    "    print('Saving Data...')\n",
    "    hf = h5py.File(savepath+swimname+'.h5', 'w')\n",
    "    hf.create_dataset('Velocities', data=Vels, compression=\"gzip\", compression_opts=1)\n",
    "    hf.close()\n",
    "\n",
    "    if visualize:\n",
    "        #print('Johnny Needs to program this still...')\n",
    "        graphFinalStroke(Vels,verts,triangles,swimname,minr,maxr,slantangle,cycletime,profilespline,difspline,savepath,minz=0,zheight=20,figheight = 10,qscale = 10,vlowlim=0,vuplim=5)\n",
    "\n",
    "    return traveldistance\n",
    "\n",
    "def solveTriVelocities(Trix,Triy,Triz,xold,yold,zold,dt,frame):\n",
    "    #Calc New Velocities\n",
    "    U = np.abs(Trix-xold)/(dt)#*streamtime\n",
    "    V = np.abs(Triy-yold)/(dt)#*streamtime\n",
    "    W = np.abs(Triz-zold)/(dt)#*streamtime\n",
    "    #Fix Sizes\n",
    "    U = np.concatenate(([0],U))\n",
    "    V = np.concatenate(([0],V))\n",
    "    W = np.concatenate(([0],W))\n",
    "\n",
    "    if frame ==0:\n",
    "            uSign = np.ones_like(U)\n",
    "            vSign = -1*np.ones_like(V)\n",
    "            wSign = np.ones_like(W)\n",
    "    else:\n",
    "            #Filters out if each vector is positive or negative\n",
    "            uSign = binarySign(np.concatenate(([1],Trix-xold)))\n",
    "            vSign = -1*binarySign(np.concatenate(([1],Triy-yold)))\n",
    "            wSign = binarySign(np.concatenate(([1],Triz-zold)))\n",
    "\n",
    "    return U,V,W, uSign,vSign,wSign\n",
    "\n",
    "#Builds a mask of points containing your swimmer/mtf that aligns with the LBM grid, and assigns them veolcities\n",
    "def solve_velocity_grid(verts,triangles,minr,maxr,thic,slantangle,cycletime,profilespline,difspline,grid,shape):\n",
    "    \n",
    "    #Build a Velocity Array from Your Objects/ MTFs/Swimmers slice by slice\n",
    "    Mslice =np.zeros((1,shape[0],shape[1],shape[2],4))\n",
    "    Norms =np.zeros((cycletime,triangles.shape[0],3))\n",
    "\n",
    "    for i in tqdm(range(cycletime),position=0, leave=True):\n",
    "        #Finds what percetage of the grid is available for contraction based on a edge pinning\n",
    "        slantr = SwimMesh.reduce_slant(verts,slantangle)\n",
    "        \n",
    "        #Returns coordinate kinematics\n",
    "        xnew,ynew,znew = SwimMesh.solveContraction(verts,minr,maxr,slantangle,slantr,i,cycletime,profilespline,difspline)\n",
    "\n",
    "        #Adjust so that MTF isn't sitting on the bottom of the tank or merged with the wall\n",
    "        znew = znew+2*thic\n",
    "        ynew = ynew+2*thic\n",
    "\n",
    "        #Returns Normal Vectors and coordinates of each triangle's centroid\n",
    "        VertNorms, TriNorm, Trix,Triy,Triz = SwimMesh.ContstructVertNorms(xnew,ynew, znew,triangles,inverse=False)\n",
    "        if i ==0:\n",
    "            xold,yold,zold = Trix,Triy,Triz\n",
    "        \n",
    "        #Returns velocity Vectors for Each Triangle using position deltas\n",
    "        U,V,W, Xsign,Ysign,Zsign = solveTriVelocities(Trix,Triy,Triz,xold,yold,zold,dt,i)\n",
    "\n",
    "        #Returns a list of points that are inside each triangle, labeled by that triangle's number, with positive indicating the topside and negative the bottom side\n",
    "        zlist = SwimMesh.fast_find_grid(xnew, ynew, znew, triangles, grid, VertNorms,thic=thic)\n",
    "        zlist = zlist.astype(np.int)\n",
    "\n",
    "        #Convert to velocities at each triangle point, building a materials interaction grid, slice by slice\n",
    "        for j in range(0,shape[2]):\n",
    "            index = np.abs(zlist[j::shape[2]]) #Index of triangles for each z slice\n",
    "            \n",
    "            #Assign New Velocities\n",
    "            zslicex = TriNorm[index,0]*U[index]*Xsign[index]\n",
    "            zslicey = TriNorm[index,1]*V[index]*Ysign[index]\n",
    "            zslicez = TriNorm[index,2]*W[index]*Zsign[index]\n",
    "            \n",
    "            zslicex = np.transpose(zslicex.reshape(shape[1],shape[0]))\n",
    "            zslicey = np.transpose(zslicey.reshape(shape[1],shape[0]))\n",
    "            zslicez = np.transpose(zslicez.reshape(shape[1],shape[0]))\n",
    "            Mslice[0,:,:,j,0] = zslicex #x velocities\n",
    "            Mslice[0,:,:,j,1] = zslicey #y velocities\n",
    "            Mslice[0,:,:,j,2] = zslicez #zvelocities\n",
    "            Mslice[0,:,:,j,3] = np.transpose(index.reshape(shape[1],shape[0])) #ObjectMask\n",
    "            Mslice[0,:,:,j,3][Mslice[0,:,:,j,3]!=0]=1 #Set all triangle values to 1\n",
    "\n",
    "        #print(Mslice.shape)\n",
    "        if i ==0:\n",
    "            Mindex_build = Mslice\n",
    "        else:\n",
    "            Mindex_build = np.concatenate((Mindex_build,Mslice),axis=0)\n",
    "            \n",
    "        #print(TriNorm.shape)\n",
    "        Norms[i,:,:] = TriNorm\n",
    "                \n",
    "        xold,yold,zold = Trix,Triy,Triz\n",
    "    \n",
    "    return Mindex_build\n",
    "\n",
    "def generateDataframe(dnalength):\n",
    "    #---Make Swimmer Dataframe with Labels ---\n",
    "    #Takes ~15 min to run for radar plot coordinates\n",
    "\n",
    "    #Generate List of all possible swimmers\n",
    "    print('Generating List....')\n",
    "    dnaAlphabet = SwimNN.SwimDNA.DNABasis()\n",
    "    fullswimlist = [''.join(i) for i in product(dnaAlphabet, repeat = dnalength)]\n",
    "    fullswimlist = fullswimlist[1:-1]\n",
    "    df = pd.DataFrame({'DNA':fullswimlist})\n",
    "    \n",
    "    print('Finding Rader Points....')\n",
    "    alphabetVectors = SwimNN.RadarPlot.constructRadarBasis(SwimNN.SwimDNA.DNABasis())\n",
    "    RadarPoints = df.DNA.apply(SwimNN.RadarPlot.DNARadarPointsList, args=(alphabetVectors,))\n",
    "    RadarPoints = pd.DataFrame(RadarPoints.to_list(),columns=['RadX','RadY'])\n",
    "    df['RadX']=RadarPoints.RadX.to_list()\n",
    "    df['RadY']=RadarPoints.RadY.to_list()\n",
    "    \n",
    "    df['SimNetU'] = np.nan\n",
    "    df['CDF'] = np.nan\n",
    "    df['ModelLabel'] = np.nan     \n",
    "          \n",
    "    return df\n",
    "\n",
    "\n",
    "def updateModelLabels(df,model,chunksize=4, dualloss = False):\n",
    "    splits = int(np.round(df.DNA.size/chunksize))\n",
    "    breakList = list(SwimNN.SwimSearch.chunks(np.arange(df.DNA.size),splits))\n",
    "    \n",
    "    modelLabel = np.zeros(df.DNA.size)\n",
    "    print('Updating Labels')\n",
    "    for breaks in breakList:\n",
    "        print(f'{(breaks[-1]/df.DNA.size)*100:.2f}%...')\n",
    "        dfchunk = df[breaks[0]:breaks[-1]+1]\n",
    "        OH_df = SwimNN.NN.OneHotEncodeList(dfchunk)\n",
    "        if dualloss:\n",
    "            #modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df[breaks[0]:breaks[-1]+1],training=False)[0].numpy().reshape(-1) #Multiloss\n",
    "            modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df,training=False)[0].numpy().reshape(-1)\n",
    "        else:\n",
    "            modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df,training=False).numpy().reshape(-1)\n",
    "            #modelLabel[breaks[0]:breaks[-1]+1] = model(OH_df[breaks[0]:breaks[-1]+1],training=False).numpy().reshape(-1)\n",
    "\n",
    "    return modelLabel\n",
    "\n",
    "def searchNearestNeighborDE(df,train,simsperloop,loopnum,seed=1337):\n",
    "    top = df[~df.DNA.isin(train.DNA)].nlargest(int(np.round(simsperloop)),'ModelLabel')\n",
    "    top['AvgDistance'] =  SwimNN.SwimDNA.avgDnaListDistance(top.DNA)\n",
    "\n",
    "    mid = top.nlargest(1,'AvgDistance').DNA.to_list()[0]\n",
    "    far = top.nsmallest(1,'AvgDistance').DNA.to_list()[0]\n",
    "\n",
    "    DNAlength = len(train.DNA.to_list()[0])\n",
    "\n",
    "    GenNum = loopnum\n",
    "    SwimNum = int(np.round(simsperloop/2))-1\n",
    "    middnalist = GeoSwimmer.GeoSwimmer.GenerateSwimArray(mid,SwimNum,GenNum,DNAlength,EvolveDNA=True,printDATA=False,insert_del=False,double=False,saveDATA = '')\n",
    "    fardnalist = GeoSwimmer.GeoSwimmer.GenerateSwimArray(far,SwimNum,GenNum,DNAlength,EvolveDNA=True,printDATA=False,insert_del=False,double=False,saveDATA = '')\n",
    "\n",
    "    #Combine into a DNA list\n",
    "    dnalist = np.append(middnalist,fardnalist)\n",
    "    dnalist = np.append(dnalist,far)\n",
    "    dnalist = np.append(dnalist,mid)\n",
    "    print(dnalist)\n",
    "    print(\"Mid: \" + mid)\n",
    "    print(\"Far: \" + far)\n",
    "    \n",
    "    #If already tested, random sample instead\n",
    "    remain = simsperloop-train[train.DNA.isin(dnalist)].DNA.size #Take random samples for the remaining simulaitons\n",
    "    if remain>0:\n",
    "        for Swim in train[train.DNA.isin(dnalist)].DNA.to_list():\n",
    "            dnalist = dnalist[dnalist!=Swim]\n",
    "        dnalist = np.append(dnalist,top[~top.DNA.isin(dnalist)].nlargest(remain,'ModelLabel').DNA.to_list())\n",
    "    return dnalist\n",
    "    \n",
    "\n",
    "def checkPrevSimulated(df,SwimList):\n",
    "    completelist = df[df[\"SimNetU\"].notna()].DNA.to_list()\n",
    "    print(len(completelist))\n",
    "    prunelist = list()\n",
    "    [prunelist.append(x) for x in SwimList if x not in completelist]\n",
    "    return prunelist\n",
    "\n",
    "def generateSwimList(df,batchsize,gennum,savepath,dnaLength=6,epochsperloop = 50,seed='1337',lr=0.001,epsilon=1e-07):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    #model = SwimNN.NN.genNN_mixed_model(dnaLength)\n",
    "    model = SwimNN.NN.Hessian_DualLoss_refine(dnaLength)\n",
    "    \n",
    "    loadweights = os.path.exists(savepath+'model.h5')\n",
    "    if loadweights == False:\n",
    "        print('No Model Weights found...proceeding with fresh weights') \n",
    "    else:\n",
    "        print('Loading Model weights...')\n",
    "        model.load_weights(savepath+'model.h5') \n",
    "        print('Model Loaded')\n",
    "    \n",
    "    \n",
    "    train = df[df[\"SimNetU\"].notna()]\n",
    "    print(f'Train min Value: {train[\"SimNetU\"].min()}')\n",
    "    print(f'Train Max Value: {train[\"SimNetU\"].max()}')\n",
    "    \n",
    "    #Estimate CDF of Training Samples\n",
    "    train_vels = np.array(train[\"SimNetU\"].to_list()) #Convert of Array\n",
    "    \n",
    "    print('Fitting CDF to array')\n",
    "    ge_c,ge_mean,ge_sigma = scipy.stats.genextreme.fit(train_vels) #Fit using extreme value thereom\n",
    "    print(f'ge_c: {ge_c}, ge_mean: {ge_mean}, ge_sigma: {ge_sigma}')\n",
    "    train['CDF'] = scipy.stats.genextreme.cdf(train.SimNetU, ge_c,loc=ge_mean,scale=ge_sigma) #-Assigned Guessed CDF\n",
    "       \n",
    "    #Generate training inputs for model\n",
    "    OH_train =tf.cast(SwimNN.NN.OneHotEncodeList(train),tf.float64)\n",
    "    train_label = tf.convert_to_tensor(train.CDF.to_numpy(),dtype=tf.float64)\n",
    "    \n",
    "    #Prep Model\n",
    "    loss = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    model.compile(optimizer=SwimNN.NN.NNOptimizer(lr=lr,epsilon=epsilon),\n",
    "              loss=(loss,loss),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Fit Model to data - Two Labels for Multiloss\n",
    "    model.fit(OH_train, (train_label,train_label), epochs=epochsperloop)\n",
    "    \n",
    "    print('Saving Model Weights...')\n",
    "    model.save_weights(savepath+'model.h5')\n",
    "    \n",
    "    df['ModelLabel'] = updateModelLabels(df,model,chunksize=32,dualloss=True) #Update database's Model Labels\n",
    "    \n",
    "    print('Searching top candidates and performing directed evolution')\n",
    "    #Estimates the most 'central' and 'exterior' DNA sample in the top predicted, and performs directed evolution to generate new swimlist\n",
    "    SwimList = searchNearestNeighborDE(df,train,batchsize,gennum,seed=seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return SwimList\n",
    "\n",
    "def colorpallette():\n",
    "    #New Gray-> Blue Colormap\n",
    "    cbits = 256\n",
    "    vals = np.ones((cbits, 4))\n",
    "    vals[:, 0] = np.linspace(245./256,20./256, cbits)\n",
    "    vals[:, 1] = np.linspace(245./256,20./256, cbits)\n",
    "    vals[:, 2] = np.linspace(245./256,120./256,  cbits)\n",
    "    cpalette = ListedColormap(vals)\n",
    "    return cpalette\n",
    "\n",
    "def graphFinalStroke(Vels,verts,triangles,swimmerDNA,minr,maxr,slantangle,cycletime,profilespline,difspline,savepath,minz=0,zheight=25,figheight = 10,qscale = 10,vlowlim=0,vuplim=5,skip=10):\n",
    "    print(\"Graphing Results....\")  \n",
    "    xpad = 64*dx\n",
    "    maxz = int(Vels.shape[3])-1\n",
    "    minx= 0\n",
    "    maxx = int(Vels.shape[1])-1\n",
    "    miny=0\n",
    "    maxy = int(Vels.shape[2])-1\n",
    "    \n",
    "    #Setup Calc- Grid Coordinates\n",
    "    x = np.linspace(-Vels.shape[1]/2, Vels.shape[1]/2, shape[0])*dx\n",
    "    y = np.linspace(0, Vels.shape[2], Vels.shape[2])*dx\n",
    "    z = np.linspace(0, Vels.shape[3], Vels.shape[3])*dx\n",
    "    xv, yv = np.meshgrid(y,x)\n",
    "    zxv, zv = np.meshgrid(z,y)\n",
    "\n",
    "    xz = np.linspace(x.min(),x.max(),Vels.shape[1])\n",
    "    yz = np.linspace(y.min(),y.max(),Vels.shape[2])\n",
    "    yzz = np.linspace(z.min(),z.max(),Vels.shape[3])\n",
    "    xs,ys = np.meshgrid(xz,yz)\n",
    "    zxvs, zvs = np.meshgrid(yz,yzz)\n",
    "\n",
    "    midp = int(np.round(Vels.shape[0]/2.0))\n",
    "    AR = float(xz[Vels.shape[1]-1]-xz[0])/float(yz[Vels.shape[2]-1]-yz[0])\n",
    "    ARside = float(yzz[maxz]-yzz[minz])/float(yz[Vels.shape[2]-1]-yz[0])\n",
    "    #sAR = u.shape[1]/float(u.shape[0])\n",
    "\n",
    "    #Figure Info\n",
    "    norm = matplotlib.colors.Normalize()\n",
    "    norm.autoscale(np.array([vlowlim,vuplim]))\n",
    "    cms = colorpallette()\n",
    "    sm = matplotlib.cm.ScalarMappable(cmap=cms, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    slantr = SwimMesh.reduce_slant(verts,slantangle)\n",
    "    for i in range(0,Vels.shape[0]):\n",
    "        #print(f'{i}/{cycletime}')\n",
    "        #Get Vectors\n",
    "        u = scipy.interpolate.griddata((yv.ravel(),xv.ravel()),Vels[i,:,:,zheight,0].ravel(),(xs,ys))\n",
    "        v = scipy.interpolate.griddata((yv.ravel(),xv.ravel()),Vels[i,:,:,zheight,1].ravel(),(xs,ys))\n",
    "\n",
    "        xnew,ynew,znew = SwimMesh.solveContraction(verts,minr,maxr,slantangle,slantr,i,cycletime,profilespline,difspline)\n",
    "        \n",
    "        #Check Velocity Save path\n",
    "        check = os.path.isdir(savepath+'\\\\VelocityTD')\n",
    "        if not check:\n",
    "            os.mkdir(savepath+'\\\\VelocityTD')\n",
    "\n",
    "        check = os.path.isdir(savepath+'\\\\VelocityTD\\\\'+swimmerDNA)\n",
    "        if not check:\n",
    "            os.mkdir(savepath+'\\\\VelocityTD\\\\'+swimmerDNA)\n",
    "        \n",
    "        M = np.sqrt(u**2+v**2)\n",
    "\n",
    "        ##Plot Velocity Top Down##\n",
    "        fig, ax = subplots(figsize=(figheight*AR,figheight))\n",
    "        ax.pcolormesh(xs,ys, M,cmap=cms,vmin=vlowlim,vmax=vuplim)\n",
    "\n",
    "        for vertices in triangles:\n",
    "            ax.plot(xnew[vertices],ynew[vertices],'r--',linewidth=3)\n",
    "            ax.plot(xnew[[vertices[-1],vertices[0]]],ynew[[vertices[-1],vertices[0]]],'r--',linewidth=3)\n",
    "\n",
    "        #q = ax.quiver(xs[::skip,::skip],ys[::skip,::skip],u[::skip,::skip],v[::skip,::skip],color='k',clim=(vlowlim,vuplim),width=0.008,scale=3,alpha=0.9)\n",
    "        q = ax.quiver(xs[::skip,::skip],ys[::skip,::skip],u[::skip,::skip],v[::skip,::skip],color='k',clim=(vlowlim,vuplim),width=0.008,scale=qscale,alpha=0.9)\n",
    "        ax.set_xlabel('X (mm)',size=30,labelpad=20)\n",
    "        ax.set_ylabel('Y (mm)',size=30,labelpad=20)\n",
    "        cbar = fig.colorbar(sm)\n",
    "        cbar.set_label(('Velocity (mm/s)'), rotation=270,fontsize=30,labelpad=30)\n",
    "        xlim(xz[minx],xz[maxx])\n",
    "        ylim(yz[miny],yz[maxy])\n",
    "        savefig(savepath+'\\\\VelocityTD\\\\'+swimmerDNA+'\\\\'+str(i)+'.png')\n",
    "        clf()\n",
    "        close()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Variables\n",
    "#Area constraints (mm)\n",
    "total_grid_size_x = 18.0 #mm\n",
    "total_grid_size_y = 12.0 #mm\n",
    "total_grid_size_z = 12.0 #mm\n",
    "\n",
    "\n",
    "ReductionFactor = 1 #Size scaling factor, default 1\n",
    "streamtime = 10 #Frames of liquid streaming per frame of object movement\n",
    "\n",
    "#Viscosity\n",
    "Re = 60 #Reynolds Number\n",
    "maxVel = 21 #mm/s\n",
    "swimmass = 1 #mass relative to density of fluid\n",
    "\n",
    "#Dependent Variable Setup\n",
    "Re = Re*ReductionFactor\n",
    "vis = 1*maxVel*2/(Re) #Rho*Vel*CharcLength/Renolds\n",
    "vis = vis*1.02 #Change based on Tyrode's estimated viscocity\n",
    "swimmass = swimmass*ReductionFactor\n",
    "\n",
    "#Time Steps\n",
    "dt = 1.0/60.0 #Second per step\n",
    "dx = 0.125#0.075 #Size of each grid space\n",
    "totalsimtime = 24.0 #in seconds\n",
    "savenum = 4 #Save every number of n frames\n",
    "\n",
    "#Image Scalling - Set to zero to remove frame\n",
    "scalemax = 4 #mm/s\n",
    "scalemax = scalemax/ReductionFactor\n",
    "\n",
    "#Stimulation\n",
    "Hz = 1.0\n",
    "cycletime = int(np.round(1 /(Hz*dt)))\n",
    "print('Cycle frames: '+ str(cycletime))\n",
    "\n",
    "#Mtf Variables - \n",
    "thic = 2*dx#.1 #Thickness of Film\n",
    "slantangle = -30.0 #Angle that the film is patterned at\n",
    "maxr = 8  #Circle max - mm\n",
    "minr = 1.4 #Circle min - mm\n",
    "\n",
    "\n",
    "#Scaling Factor for Swimmers - Default = 5 for ~ 5 mm max width swimmers\n",
    "wscale = 4\n",
    "\n",
    "#Unit Conversion (pica to mm)\n",
    "picatoMM = 6.4/1.696 #mm/pica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup From Constants\n",
    "xsize = np.round(total_grid_size_x/(float(dx)*2))*2\n",
    "ysize = np.round(total_grid_size_y/(float(dx)*2))*2\n",
    "zsize = np.round(total_grid_size_z/(float(dx)*2))*2\n",
    "shape = np.array([int(xsize), int(ysize), int(zsize)])\n",
    "\n",
    "print('grid points: ' + str(shape))\n",
    "\n",
    "profile = np.loadtxt('Contraction_profile2.txt') # Contraction profile from MTF kymograph, determining film bending rate\n",
    "\n",
    "#Spline fitting of contraction profile to make it a continuose function\n",
    "t = np.linspace(0,1,profile.size)\n",
    "profilespline = UnivariateSpline(t,profile,k=3,s=.001)\n",
    "\n",
    "#Derivative of Change - determing transition from angled to flat MTFs\n",
    "t = np.linspace(0,10,30)\n",
    "a,b = 3,-0.2\n",
    "g = scipy.stats.gamma(a,b).pdf(t)\n",
    "g = g/g.max()\n",
    "g = (1-g)*0.58 #0.58 is based on relative angled cantilever contraction\n",
    "dif = g\n",
    "\n",
    "difspline = UnivariateSpline(np.linspace(0,1,dif.size),dif,k=3,s=.001)\n",
    "print('Contraction Profile Loaded...')\n",
    "\n",
    "\n",
    "\n",
    "#print('Swim Width: '+ str(np.max(verts[:,0])-np.min(verts[:,0])))\n",
    "#print('Swim Height: '+ str((np.max(verts[:,1])-np.min(verts[:,1]))*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mass Run of Angles\n",
    "\n",
    "#Initial Swimmer Simulation Conditions\n",
    "SeedDNA = 'DBGDBG' #Random seed to initialize which inputs to initially search\n",
    "\n",
    "\n",
    "savepath = 'G:\\\\....\\\\' #Filepath of where to save the outputs. Should end in a folder location denoted by '\\\\'\n",
    "initialbatch = 200 #How many swimmers to train on in the initial search\n",
    "batchsize = 50#24\n",
    "generations = 20 #Number of generations to search\n",
    "BaseLength = 6 #number of sDNA basis functions to include in a swimmer\n",
    "slantangle = -30 #Fin print angle\n",
    "epochsperloop = 50\n",
    "Visualize = True #Save visualization data for each sDNA sequence\n",
    "\n",
    "\n",
    "#Record Swimmers Completed\n",
    "completecheck = os.path.exists(savepath+'results.pkl')\n",
    "if completecheck == False:\n",
    "    print('Generating Data frame structure (Takes ~15 min)')\n",
    "    df = generateDataframe(BaseLength)\n",
    "    df.to_pickle(savepath+'results_new.pkl')\n",
    "else:\n",
    "    print('Loading Dataframe...')\n",
    "    df = pd.read_pickle(savepath+'results.pkl')\n",
    "    print('Dataframe Loaded')\n",
    "\n",
    "gentest = os.path.exists(savepath+'currentgen.txt')\n",
    "if gentest == False:\n",
    "    currentgen = np.zeros(1,dtype=int)\n",
    "    #currentgen = int(currentgen)\n",
    "    np.savetxt(savepath+\"currentgen.txt\",currentgen)\n",
    "    currentgen = 0\n",
    "\n",
    "else:\n",
    "    currentgen = int(np.genfromtxt(savepath+\"currentgen.txt\").tolist())\n",
    "print(f'Current Generation:{currentgen}')\n",
    "    \n",
    "#Main loop- Running For Swimmer Data    \n",
    "print(currentgen+generations)\n",
    "for gennum in range(currentgen,currentgen+generations):\n",
    "    print(f'Running Generation: {gennum}')\n",
    "    \n",
    "    SwimList = list('')\n",
    "    \n",
    "    if os.path.exists(savepath+'CurrentSwimlist.txt'):\n",
    "        SwimList = np.loadtxt(savepath+'CurrentSwimlist.txt',dtype=np.str)\n",
    "    \n",
    "    SwimList = checkPrevSimulated(df,SwimList)\n",
    "    \n",
    "    if len(SwimList)<= 0:\n",
    "        #Prepare list of swimmers to simulate\n",
    "        if gennum == 0:\n",
    "            seededlist = SwimNN.SwimSearch.seededList(df)\n",
    "            lenSeedList = len(seededlist.index)\n",
    "            if initialbatch>lenSeedList:\n",
    "                SwimList = seededlist.DNA.to_list()\n",
    "            else:\n",
    "                SwimList = list('')\n",
    "\n",
    "            remaining = initialbatch-len(SwimList)\n",
    "            seedint = GeoSwimmer.GeoSwimmer.seedtoInt(SeedDNA)%2**30\n",
    "            SwimList = SwimList+ df.sample(remaining,random_state=seedint).DNA.to_list()\n",
    "            print('Initial Sample')\n",
    "        else:\n",
    "            seedint = (GeoSwimmer.GeoSwimmer.seedtoInt(SeedDNA)+(gennum*batchsize))%2**30\n",
    "            SwimList = generateSwimList(df,batchsize,gennum,savepath,dnaLength=BaseLength,epochsperloop = epochsperloop,seed=seedint)\n",
    "            np.savetxt(savepath+\"currentgen.txt\",np.array([gennum]))\n",
    "            \n",
    "            #SaveRadarPlot\n",
    "            check = os.path.isdir(savepath+'\\\\RadarPlot')\n",
    "            if not check:\n",
    "                os.mkdir(savepath+'\\\\RadarPlot')\n",
    "\n",
    "            sample = df.sample(20000,random_state=seedint)\n",
    "            fig = SwimNN.RadarPlot.PlotRadarMesh(sample.RadX,sample.RadY,sample.ModelLabel,figheight=10,figwidth=10)\n",
    "            savefig(savepath + \"\\\\RadarPlot\\\\\"+str(df[df[\"SimNetU\"].notna()].DNA.size)+\".png\")\n",
    "            \n",
    "\n",
    "            \n",
    "            print(f'NewSwimmers: {SwimList}')\n",
    "    \n",
    "    print(SwimList)\n",
    "    #Test If you have run swimmers before\n",
    "    SwimList = checkPrevSimulated(df,SwimList)\n",
    "    np.savetxt(savepath+'CurrentSwimlist.txt',SwimList,fmt='%s')\n",
    "\n",
    "    \n",
    "    #Simulate Swimmers\n",
    "    for swimname in SwimList:\n",
    "        print('Running: '+str(swimname))\n",
    "        swimnum = df[df[\"SimNetU\"].notna()].DNA.size\n",
    "        print(f'SwimmerNum: {swimnum}')\n",
    "        tf.compat.v2.keras.backend.clear_session()\n",
    "\n",
    "        distancetravelled = SimSwimmer(swimname,slantangle,total_grid_size_x,total_grid_size_y,total_grid_size_z,shape,swimmass=swimmass,visualize=Visualize,savepath=savepath)\n",
    "        print(f'Swimmer Travel Distance: {distancetravelled}')\n",
    "        \n",
    "        df.loc[df[df.DNA.isin([swimname])].index,\"SimNetU\"] = distancetravelled\n",
    "        df.loc[df[df.DNA.isin([swimname])].index,\"GenNum\"] = gennum\n",
    "        df.loc[df[df.DNA.isin([swimname])].index,\"time\"] = time.time()\n",
    "        df.to_pickle(savepath+'results_updated.pkl')\n",
    "        if (swimnum%100 == 0):\n",
    "            df.to_pickle(savepath+'results_'+str(swimnum)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Simulate a Single sDNA Sequence\n",
    "swimname = 'GLIDAA'\n",
    "\n",
    "#Filepath of where to save the outputs. Should end in a folder location denoted by '\\\\'\n",
    "savepath = 'G:\\\\...\\\\'\n",
    "\n",
    "slantangle = -30\n",
    "Visualize = True\n",
    "\n",
    "distancetravelled = SimSwimmer(swimname,slantangle,total_grid_size_x,total_grid_size_y,total_grid_size_z,shape,swimmass=swimmass,visualize=Visualize,savepath=savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCustomColorMap(im_gray) :\n",
    "    cbits = 256\n",
    "    lut = np.zeros((256, 1, 3), dtype=np.uint8)\n",
    "\n",
    "    #Red\n",
    "    lut[:, 0, 0] = np.linspace(245,20, cbits, dtype=np.uint8)[:]\n",
    "    #Green\n",
    "    lut[:, 0, 1] = np.linspace(245,20, cbits, dtype=np.uint8)[:]\n",
    "\n",
    "    #Blue\n",
    "    lut[:, 0, 2] = np.linspace(245,120,  cbits, dtype=np.uint8)[:]\n",
    "    print(lut)\n",
    "    #Apply custom colormap through LUT\n",
    "    im_color = cv2.LUT(im_gray, lut)\n",
    "    \n",
    "    return im_color;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorpallette():\n",
    "    #New Gray-> Blue Colormap\n",
    "    cbits = 256\n",
    "    vals = np.ones((cbits, 4))\n",
    "    vals[:, 0] = np.linspace(245./256,20./256, cbits)\n",
    "    vals[:, 1] = np.linspace(245./256,20./256, cbits)\n",
    "    vals[:, 2] = np.linspace(245./256,120./256,  cbits)\n",
    "    cpalette = ListedColormap(vals)\n",
    "    return cpalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_custom_colormap(image_gray):\n",
    "\n",
    "    assert image_gray.dtype == np.uint8, 'must be np.uint8 image'\n",
    "    if image_gray.ndim == 3: image_gray = image_gray.squeeze(-1)\n",
    "\n",
    "    # Initialize the matplotlib color map\n",
    "    cms = colorpallette()\n",
    "    sm = matplotlib.cm.ScalarMappable(cmap=cms)\n",
    "\n",
    "    # Obtain linear color range\n",
    "    color_range = sm.to_rgba(np.linspace(0, 1, 256))[:,0:3]    # color range RGBA => RGB\n",
    "    color_range = (color_range*255.0).astype(np.uint8)         # [0,1] => [0,255]\n",
    "    color_range = np.squeeze(np.dstack([color_range[:,2], color_range[:,1], color_range[:,0]]), 0)  # RGB => BGR\n",
    "\n",
    "    # Apply colormap for each channel individually\n",
    "    channels = [cv2.LUT(image_gray, color_range[:,i]) for i in range(3)]\n",
    "    return np.dstack(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_LBM",
   "language": "python",
   "name": "tf_lbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
